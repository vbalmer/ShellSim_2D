{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Start Executing FEM_Q Script\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from Main_vb import main_solver\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import numpy file from sampler\n",
    "numpy_sampler = False\n",
    "single_sample = True\n",
    "\n",
    "path = '..\\\\01_SamplingFeatures'\n",
    "if numpy_sampler:\n",
    "        # name = 'data_240724_1752_case4\\outfile.npy'\n",
    "        name = 'data_20241104_1545_case8\\outfile.npy'\n",
    "        features = np.load(os.path.join(path, name))\n",
    "else: \n",
    "        name = 'output\\\\data_20241111_0904_case10\\\\outfile.pkl'\n",
    "        with open(os.path.join(path, name),'rb') as handle:\n",
    "                in_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# import mat_res.pkl from data that was used for training of algorithm\n",
    "path_mat_res = '..\\\\02_Simulator'\n",
    "# name = 'Simulator\\\\results\\saved_runs\\data_240805_1134_case4\\mat_res.pkl'        # take 240805 here, as there the SN are included\n",
    "# name = 'Simulator\\\\results\\saved_runs\\data_20241104_1854_case8\\mat_res.pkl'\n",
    "name = 'Simulator\\\\results\\saved_runs\\data_20241111_1101_case10\\mat_res.pkl'\n",
    "with open(os.path.join(path_mat_res, name),'rb') as handle:\n",
    "        mat_res = pickle.load(handle)\n",
    "\n",
    "# define location of trained model and input data to be used\n",
    "path_train = '..\\\\04_Training'\n",
    "\n",
    "data_path = {\n",
    "        # \"_\": os.path.join(path_train,'new_data\\\\_simple_logs\\\\v_80'),\n",
    "        \"_I\": os.path.join(path_train,'new_data\\\\_simple_logs\\\\v_198'),\n",
    "        \"_II\": os.path.join(path_train,'new_data\\\\_simple_logs\\\\v_198'),\n",
    "        \"_III\": os.path.join(path_train,'new_data\\\\_simple_logs\\\\v_198'),\n",
    "}\n",
    "model_path = {\n",
    "        # \"D\": os.path.join(path_train,'logs\\\\train_log\\\\version_83_main\\\\checkpoints\\\\best_model.ckpt'),\n",
    "        # \"m\": os.path.join(path_train,'logs\\\\train_log\\\\version_128\\\\checkpoints\\\\best_model_m.ckpt'),\n",
    "        # \"b\": os.path.join(path_train,'logs\\\\train_log\\\\version_128\\\\checkpoints\\\\best_model_b.ckpt'),\n",
    "        # \"s\": os.path.join(path_train,'logs\\\\train_log\\\\version_128\\\\checkpoints\\\\best_model_s.ckpt'),\n",
    "        #\"sig\": os.path.join(path_train, 'new_data\\\\_simple_logs\\\\v_80\\\\best_trained_model__5138.pt'),\n",
    "        \"sig_I\": os.path.join(path_train, 'new_data\\\\_simple_logs\\\\v_198\\\\best_trained_model__9997.pt'),\n",
    "        \"sig_II\": os.path.join(path_train, 'new_data\\\\_simple_logs\\\\v_198\\\\best_trained_model__9997.pt'),\n",
    "        \"sig_III\": os.path.join(path_train, 'new_data\\\\_simple_logs\\\\v_198\\\\best_trained_model__9997.pt'),\n",
    "}\n",
    "\n",
    "path_collection = {\n",
    "        \"model\": model_path,\n",
    "        \"data\": data_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a check, in mat_tot (from sampling) (t1_tot =  5 mm) should be equal to t1 in mat_res (directly read) (t1_res =  30.0 mm).\n",
      "      L     B    E_1  E_2   ms      F  F_N   s  t_1  t_2  nl  nu_1  nu_2  mat\n",
      "0  1500  1500  70000  300  150  0.005    0  20    5  0.4   5  0.23   0.5   10\n"
     ]
    }
   ],
   "source": [
    "# Inputs for iteration\n",
    "\n",
    "# If the data comes from the sampler:\n",
    "if numpy_sampler:\n",
    "    mat_tot_dict = {\n",
    "        'L': features[:,0],         # length\n",
    "        'B': features[:,1],         # width\n",
    "        'E_1': features[:,2],       # Young's modulus steel / glass / concrete\n",
    "        'E_2': features[:,3],       # Young's modulus - / interlayer / reinforcing steel\n",
    "        'ms': features[:,4],        # mesh_size\n",
    "        'F': features[:,5],         # force_magnitude\n",
    "        's': features[:,6],         # scenario 0...6\n",
    "        't_1': features[:,7],       # thickness of the plate\n",
    "        't_2': features[:,8],       # thickness of plate\n",
    "        'nl': features[:,9],        # amount of layers\n",
    "        'nu_1': features[:,10],     # Poisson's ratio\n",
    "        'nu_2': features[:,11],     # Poisson's ratio\n",
    "        'mat': features[:,12]       # Material type     (1 = lin.el., 3 = CMM, 10 = glass)\n",
    "    }\n",
    "elif numpy_sampler == False: \n",
    "    mat_tot_dict = in_dict\n",
    "\n",
    "if single_sample:\n",
    "    # # pure shear force (scenario 10)\n",
    "    # mat_tot_dict = {\n",
    "    #     'L': np.array([7500]),\n",
    "    #     'B': np.array([7500]),\n",
    "    #     'E_1': np.array([33600]),\n",
    "    #     'E_2': np.array([0]),\n",
    "    #     'ms': np.array([750]),\n",
    "    #     'F': np.array([750000]),       #=10*L\n",
    "    #     'F_N': np.array([0]),         # not required in this case\n",
    "    #     's': np.array([8]),\n",
    "    #     't_1': np.array([200]),\n",
    "    #     't_2': np.array([0]),\n",
    "    #     'nl': np.array([20]),\n",
    "    #     'nu_1': np.array([0.2]),\n",
    "    #     'nu_2': np.array([0]),\n",
    "    #     'mat': np.array([1])\n",
    "    # }\n",
    "\n",
    "    # # moment + normal force (scenario 11)\n",
    "    # mat_tot_dict = {\n",
    "    #     'L': np.array([7500]),\n",
    "    #     'B': np.array([7500]),\n",
    "    #     'E_1': np.array([33600]),\n",
    "    #     'E_2': np.array([0]),\n",
    "    #     'ms': np.array([750]),\n",
    "    #     'F': np.array([0.015]),           # Uniformly distributed load in z-direction\n",
    "    #     'F_N': np.array([750000]),       # Normal force (n[N/m]*L); e.g. n=50kN/m --> F_N = 100*7500 = 750000\n",
    "    #     's': np.array([11]),\n",
    "    #     't_1': np.array([200]),\n",
    "    #     't_2': np.array([0]),\n",
    "    #     'nl': np.array([20]),\n",
    "    #     'nu_1': np.array([0.2]),\n",
    "    #     'nu_2': np.array([0]),\n",
    "    #     'mat': np.array([1])\n",
    "    # }\n",
    "\n",
    "    # moment (scenario 10)\n",
    "    # mat_tot_dict = {\n",
    "    #     'L': np.array([7500]),\n",
    "    #     'B': np.array([7500]),\n",
    "    #     'E_1': np.array([33600]),\n",
    "    #     'E_2': np.array([0]),\n",
    "    #     'ms': np.array([750]),\n",
    "    #     'F': np.array([0.015]),\n",
    "    #     'F_N': np.array([0]),       # not required in this case.\n",
    "    #     's': np.array([10]),\n",
    "    #     't_1': np.array([200]),\n",
    "    #     't_2': np.array([0]),\n",
    "    #     'nl': np.array([20]),\n",
    "    #     'nu_1': np.array([0.2]),\n",
    "    #     'nu_2': np.array([0]),\n",
    "    #     'mat': np.array([1])\n",
    "    # }\n",
    "\n",
    "    # bending 2D (for glass; scenario 20)\n",
    "    mat_tot_dict = {\n",
    "        'L': np.array([1500]),\n",
    "        'B': np.array([1500]),\n",
    "        'E_1': np.array([70000]),\n",
    "        'E_2': np.array([300]),\n",
    "        'ms': np.array([150]),\n",
    "        'F': np.array([0.005]),\n",
    "        'F_N': np.array([0]),       # not required in this case.\n",
    "        's': np.array([20]),\n",
    "        't_1': np.array([5]),\n",
    "        't_2': np.array([0.4]),\n",
    "        'nl': np.array([5]),\n",
    "        'nu_1': np.array([0.23]),\n",
    "        'nu_2': np.array([0.5]),\n",
    "        'mat': np.array([10])\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "mat_tot_raw = pd.DataFrame.from_dict(mat_tot_dict)\n",
    "\n",
    "\n",
    "# Choose the simulation number(s) that shall be tested\n",
    "# desired_SN = [21, 32, 45, 74, 76, 82]\n",
    "desired_SN = [0]\n",
    "mat_tot = mat_tot_raw.iloc[[np.where(mat_res['SN'] == i)[0][0] for i in desired_SN]]\n",
    "mat_tot.reset_index(drop=True, inplace=True)\n",
    "print('As a check, in mat_tot (from sampling) (t1_tot = ', round(mat_tot['t_1'][0], 1), 'mm) should be equal to t1 in mat_res (directly read) (t1_res = ', round(mat_res['t_1'][desired_SN[0]],1), 'mm).')\n",
    "# print(mat_tot)\n",
    "\n",
    "conv_plt = True\n",
    "simple = True                          # Leave this on \"True\" for deployment.\n",
    "NN_hybrid = {\n",
    "    'predict_D': False,                 # If true, solves the system with NN_hybrid solver (prediction of D); if False: \"normal\" solver\n",
    "    'predict_sig': True               # If true, solves the system with NN_hybrid solver (prediction of sig); if False: \"normal\" solver\n",
    "    }\n",
    "# Note: predict_D should not be used in lin.el. case, as there is only one initialisation and this happens with lin.el. model. \n",
    "# => for lin.el. always set predict_D = False\n",
    "# \n",
    "\n",
    "print(mat_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "1 Start Meshing with gmsh\n",
      "-------------------------------------------------------\n",
      "1.1 Assemble Model and mesh\n",
      "1.2 Boundary Conditions and Loads\n",
      "1.3 Read Material, Constitutive Model and Integration Options\n",
      "1.4 Postprocess Mesh\n",
      "   1.41 Node Coordinates\n",
      "   1.42 Node Connectivity\n",
      "   1.43 Element Center Information 1/2\n",
      "   1.44 Element Numbering\n",
      "   1.45 Global Coordinate Transformation\n",
      "   1.46 Node Information\n",
      "   1.47 Flip Element Arrangement Clockwise\n",
      "   1.48 Element Center Information 2/2\n",
      "   1.49 Element Connectivity\n",
      "   1.410 Element Integration Point Information\n",
      "   1.411 Geometrical Information per Element\n",
      "   1.412 Material Information per Element\n",
      "   1.413 Masks for Nodes in Areas\n",
      "   1.414 Coplanar Nodes\n",
      "-------------------------------------------------------\n",
      "2 Solution\n",
      "-------------------------------------------------------\n",
      "2.1 Assembly of force vector and condensed DOFs\n",
      "2.2 Solution for Linear Elasticity\n",
      "Some values are outside the lin.el. strain boundaries. Chosen model is still model III.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbalmer\\Documents\\GitHub\\ShellSim\\05_Deploying\\NN_call.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(lit_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss order for NN-run is:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbalmer\\Documents\\GitHub\\ShellSim\\05_Deploying\\Main_vb.py:575: RuntimeWarning: invalid value encountered in divide\n",
      "  rele = np.divide(diffe,eh)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some values are outside the lin.el. strain boundaries. Chosen model is still model III.\n",
      "2.4 Solution complete\n",
      " - Maximum displacements:\n",
      "   - ux_max = 0.0\n",
      "   - uy_max = 0.0\n",
      "   - uz_max = 4.762\n",
      " - Sum of applied forces:\n",
      "   - Fx = 0.0\n",
      "   - Fy = 0.0\n",
      "   - Fz = -11250.0\n",
      " - Sum of reaction forces:\n",
      "   - Rx = -38.7\n",
      "   - Ry = -46.3\n",
      "   - Rz = 6846.4\n",
      "total time used:  19.171040296554565\n",
      "time used in stress calculation 0\n",
      "time used in strain calculation 0\n",
      "time used in stiffness matrix calculation 1.5283691883087158\n",
      "time used in B-matrix calculation 8.480615854263306\n",
      "time used in stiffness matrix inversion 0\n",
      "time used in calculation of sh 17.616660833358765\n",
      "time used in calculation of eh 0.2383110523223877\n",
      "-------------------------------------------------------\n",
      "3 Postprocess Data\n",
      "-------------------------------------------------------\n",
      "Finished :)\n"
     ]
    }
   ],
   "source": [
    "# DO NOT ADJUST THIS CODE BLOCK\n",
    "\n",
    "samples = int(mat_tot.shape[0])\n",
    "n_simple = len(desired_SN)\n",
    "\n",
    "if simple:\n",
    "    mat_res = [dict() for x in range(n_simple)]\n",
    "    for i in range(int(n_simple)):\n",
    "        mat = mat_tot.loc[i,:]\n",
    "        mat_res[i] = main_solver(mat,conv_plt, NN_hybrid, path_collection)\n",
    "        if i>0 and i%10 == 0:\n",
    "            print('**********************************************************************')\n",
    "            print('Data points upto row', i, 'are simulated')\n",
    "            print('time required for first', i,'points:',time.time()-t0, 'secs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ms</th>\n",
       "      <th>L</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ms       L       B\n",
       "0  150.0  1500.0  1500.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if NN_hybrid['predict_sig'] and NN_hybrid['predict_D']: \n",
    "    fname = 'mat_res_NN.pkl'\n",
    "elif NN_hybrid['predict_sig']:\n",
    "    fname = 'mat_res_NN_sig.pkl'\n",
    "elif NN_hybrid['predict_D']:\n",
    "    fname = 'mat_res_NN_D.pkl'\n",
    "else: \n",
    "    fname = 'mat_res_norm.pkl'\n",
    "\n",
    "mat_res_pd_NN = pd.DataFrame.from_dict(mat_res)\n",
    "mat_res_pd_NN.to_pickle(os.path.join('data_out',fname))\n",
    "mat_res_pd_NN[['ms', 'L', 'B']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mat_res_pd_NN['uz'][0])\n",
    "# print(mat_res_pd_NN['thx'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "1 Start Meshing with gmsh\n",
      "-------------------------------------------------------\n",
      "1.1 Assemble Model and mesh\n",
      "1.2 Boundary Conditions and Loads\n",
      "1.3 Read Material, Constitutive Model and Integration Options\n",
      "1.4 Postprocess Mesh\n",
      "   1.41 Node Coordinates\n",
      "   1.42 Node Connectivity\n",
      "   1.43 Element Center Information 1/2\n",
      "   1.44 Element Numbering\n",
      "   1.45 Global Coordinate Transformation\n",
      "   1.46 Node Information\n",
      "   1.47 Flip Element Arrangement Clockwise\n",
      "   1.48 Element Center Information 2/2\n",
      "   1.49 Element Connectivity\n",
      "   1.410 Element Integration Point Information\n",
      "   1.411 Geometrical Information per Element\n",
      "   1.412 Material Information per Element\n",
      "   1.413 Masks for Nodes in Areas\n",
      "   1.414 Coplanar Nodes\n",
      "-------------------------------------------------------\n",
      "2 Solution\n",
      "-------------------------------------------------------\n",
      "2.1 Assembly of force vector and condensed DOFs\n",
      "2.2 Solution for Linear Elasticity\n",
      "Gauss order for NLFEA-run is:  2\n",
      "2.4 Solution complete\n",
      " - Maximum displacements:\n",
      "   - ux_max = 0.0\n",
      "   - uy_max = 0.0\n",
      "   - uz_max = 4.762\n",
      " - Sum of applied forces:\n",
      "   - Fx = 0.0\n",
      "   - Fy = 0.0\n",
      "   - Fz = -11250.0\n",
      " - Sum of reaction forces:\n",
      "   - Rx = 0.0\n",
      "   - Ry = 0.0\n",
      "   - Rz = 8882.6\n",
      "total time used:  5.631768465042114\n",
      "time used in stress calculation 0.9381775856018066\n",
      "time used in strain calculation 1.8631064891815186\n",
      "time used in stiffness matrix calculation 2.4815073013305664\n",
      "time used in B-matrix calculation 15.056225538253784\n",
      "time used in stiffness matrix inversion 0\n",
      "time used in calculation of sh 17.916130304336548\n",
      "time used in calculation of eh 0.92500901222229\n",
      "-------------------------------------------------------\n",
      "3 Postprocess Data\n",
      "-------------------------------------------------------\n",
      "Finished :)\n"
     ]
    }
   ],
   "source": [
    "# run the same simulation but without the NN (--> ground truth)\n",
    "NN_hybrid_2 = {'predict_D': False,\n",
    "             'predict_sig': False}                       # If true, solves the system with NN_hybrid solver; if False: \"normal\" solver\n",
    "samples = int(mat_tot.shape[0])\n",
    "n_simple = len(desired_SN)\n",
    "\n",
    "\n",
    "if simple:\n",
    "    mat_res = [dict() for x in range(n_simple)]\n",
    "    for i in range(int(n_simple)):\n",
    "        mat = mat_tot.loc[i,:]\n",
    "        # with HiddenPrints():\n",
    "        mat_res[i] = main_solver(mat,conv_plt, NN_hybrid_2, model_path)\n",
    "        if i>0 and i%10 == 0:\n",
    "            print('**********************************************************************')\n",
    "            print('Data points upto row', i, 'are simulated')\n",
    "            print('time required for first', i,'points:',time.time()-t0, 'secs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ms</th>\n",
       "      <th>L</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ms       L       B\n",
       "0  150.0  1500.0  1500.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save relevant parameters\n",
    "if NN_hybrid_2['predict_sig'] and NN_hybrid_2['predict_D']: \n",
    "    fname = 'mat_res_NN.pkl'\n",
    "elif NN_hybrid_2['predict_sig']:\n",
    "    fname = 'mat_res_NN_sig.pkl'\n",
    "elif NN_hybrid_2['predict_D']:\n",
    "    fname = 'mat_res_NN_D.pkl'\n",
    "else: \n",
    "    fname = 'mat_res_norm.pkl'\n",
    "\n",
    "mat_res_pd = pd.DataFrame.from_dict(mat_res)\n",
    "mat_res_pd.to_pickle(os.path.join('data_out',fname))\n",
    "\n",
    "mat_res_pd.head()\n",
    "mat_res_pd[['ms', 'L', 'B']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0 is copied to data_out\\data_20250207_1154_casexx\\mat_res_norm.pkl\n",
      "File 1 is copied to data_out\\data_20250207_1154_casexx\\mat_res_NN_sig.pkl\n"
     ]
    }
   ],
   "source": [
    "# if data should be saved to folder instead of being overwritten with the next simulation, use save_folder = True\n",
    "\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "save_folder = True\n",
    "\n",
    "if save_folder:\n",
    "    if NN_hybrid['predict_sig'] and NN_hybrid['predict_D']:\n",
    "        relative_path = ['data_out\\\\mat_res_norm.pkl', 'data_out\\\\mat_res_NN.pkl']\n",
    "    elif NN_hybrid['predict_sig']:\n",
    "        relative_path = ['data_out\\\\mat_res_norm.pkl', 'data_out\\\\mat_res_NN_sig.pkl']\n",
    "    elif NN_hybrid['predict_D']:\n",
    "        relative_path = ['data_out\\\\mat_res_norm.pkl', 'data_out\\\\mat_res_NN_D.pkl']\n",
    "    \n",
    "    for i in range(len(relative_path)):\n",
    "        source_folder = os.path.dirname(relative_path[i])\n",
    "        file_name = os.path.basename(relative_path[i])\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        new_folder = current_time.strftime(\"data_%Y%m%d_%H%M_case\"+'xx')\n",
    "        new_folder_path = os.path.join(source_folder, new_folder)\n",
    "\n",
    "        os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "        destination_path = os.path.join(new_folder_path, file_name)\n",
    "        shutil.copy(relative_path[i], destination_path)\n",
    "\n",
    "        print('File', i, 'is copied to', destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    150.0\n",
      "Name: ms, dtype: float64\n",
      "0    5.0\n",
      "Name: t_1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(mat_res_pd.keys())\n",
    "# print(mat_res_pd['eps_g'][0].shape)\n",
    "# print(mat_res_pd['eps_g'][0][:,0,0,0]) # these should correspond to eps_x\n",
    "# print(mat_res_pd['eps_g'][0][:,0,0,7]) # these should correspond to gamma_xz\n",
    "print(mat_res_pd['ms'])\n",
    "print(mat_res_pd['t_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchwise iteration not necessarily required for deployment\n",
    "\n",
    "\n",
    "# iterate batchwise over all input sets (here: 3 batches which are created automatically based on size of input vector)\n",
    "# else:\n",
    "#     mat_res = [dict() for x in range(samples)]\n",
    "#     for i in range(int(samples/3)):\n",
    "#         mat = mat_tot.loc[i,:]\n",
    "#         with HiddenPrints():\n",
    "#             mat_res[int(i)] = main_solver(mat,conv_plt, NN_hybrid, model_path)\n",
    "#         if i>0 and i%10 == 0:\n",
    "#             print('**********************************************************************')\n",
    "#             print('Data points upto row', i, 'are simulated')\n",
    "#             print('time required for first', i,'points:',time.time()-t0, 'secs')\n",
    "        \n",
    "#     for i in np.linspace(\n",
    "#         int(samples/3), \n",
    "#         2*int(samples/3), \n",
    "#         (2*int(samples/3)-int(samples/3))+1\n",
    "#         ):\n",
    "#         mat = mat_tot.loc[i,:]\n",
    "#         with HiddenPrints():\n",
    "#             mat_res[int(i)] = main_solver(mat,conv_plt, NN_hybrid, model_path)\n",
    "#         if i%10 == 0:\n",
    "#             print('**********************************************************************')\n",
    "#             print('Data points upto row', i, 'are simulated')\n",
    "#             print('time required for first', i, 'points:',time.time()-t0, 'secs')\n",
    "\n",
    "#     for i in np.linspace(\n",
    "#         2*int(samples/3), \n",
    "#         int(samples), \n",
    "#         (2*int(samples/3)-int(samples/3))+1\n",
    "#         ):\n",
    "#         mat = mat_tot.loc[int(i-1),:]\n",
    "#         with HiddenPrints():\n",
    "#             mat_res[int(i-1)] = main_solver(mat,conv_plt, NN_hybrid, model_path)\n",
    "#         if (i-1)%10 == 0:\n",
    "#             print('**********************************************************************')\n",
    "#             print('Data points upto row', i-1, 'are simulated')\n",
    "#             print('time required for first', i-1, 'points:',time.time()-t0, 'secs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShellSim_vb_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
